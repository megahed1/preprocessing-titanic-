{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bbf41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "# Handling missing values\n",
    "# Removing duplicates\n",
    "# Data type conversions\n",
    "# Basic data transformations\n",
    "# Handling outliers\n",
    "# Encoding categorical variables\n",
    "# Scaling/normalizing data\n",
    "# Renaming columns\n",
    "# Handling inconsistent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439b3337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "      Name   Age Gender   Salary  Start Date\n",
      "0    Alice  24.0      F  50000.0  2020-01-15\n",
      "1      Bob  27.0      M  54000.0  2019-03-22\n",
      "2  Charlie  22.0      M  50000.0  2018-06-30\n",
      "3    David  32.0      M  52000.0  2015-09-01\n",
      "4   Edward  29.0   None  58000.0  2016-10-12\n",
      "5     None  23.0      M  50000.0  2020-11-20\n",
      "6    Frank   NaN      M  59000.0  2017-02-10\n",
      "7    Grace  21.0      F      NaN  2018-07-19\n",
      "8   Hannah  25.0      F  60000.0  2019-08-25\n",
      "9      Ian  28.0      M  58000.0  2018-12-11\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning Notebook for Beginners\n",
    "\n",
    "# ## Introduction\n",
    "# In this notebook, we'll cover some basic and advanced data cleaning techniques using Python and the pandas library.\n",
    "\n",
    "# ## 1. Loading Data\n",
    "# First, let's import the necessary libraries and load a sample dataset.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data in a CSV file (You can replace this with your actual data file)\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', None, 'Frank', 'Grace', 'Hannah', 'Ian'],\n",
    "    'Age': [24, 27, 22, 32, 29, 23, None, 21, 25, 28],\n",
    "    'Gender': ['F', 'M', 'M', 'M', None, 'M', 'M', 'F', 'F', 'M'],\n",
    "    'Salary': [50000, 54000, 50000, 52000, 58000, 50000, 59000, None, 60000, 58000],\n",
    "    'Start Date': ['2020-01-15', '2019-03-22', '2018-06-30', '2015-09-01', '2016-10-12', '2020-11-20', '2017-02-10', '2018-07-19', '2019-08-25', '2018-12-11']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fe8b9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data with Filled Missing Values:\n",
      "      Name        Age   Gender   Salary  Start Date\n",
      "0    Alice  24.000000        F  50000.0  2020-01-15\n",
      "1      Bob  27.000000        M  54000.0  2019-03-22\n",
      "2  Charlie  22.000000        M  50000.0  2018-06-30\n",
      "3    David  32.000000        M  52000.0  2015-09-01\n",
      "4   Edward  29.000000  Unknown  58000.0  2016-10-12\n",
      "5  Unknown  23.000000        M  50000.0  2020-11-20\n",
      "6    Frank  25.666667        M  59000.0  2017-02-10\n",
      "7    Grace  21.000000        F  54000.0  2018-07-19\n",
      "8   Hannah  25.000000        F  60000.0  2019-08-25\n",
      "9      Ian  28.000000        M  58000.0  2018-12-11\n",
      "\n",
      "Data with Dropped Missing Values:\n",
      "      Name   Age Gender   Salary  Start Date\n",
      "0    Alice  24.0      F  50000.0  2020-01-15\n",
      "1      Bob  27.0      M  54000.0  2019-03-22\n",
      "2  Charlie  22.0      M  50000.0  2018-06-30\n",
      "3    David  32.0      M  52000.0  2015-09-01\n",
      "8   Hannah  25.0      F  60000.0  2019-08-25\n",
      "9      Ian  28.0      M  58000.0  2018-12-11\n"
     ]
    }
   ],
   "source": [
    "# ## 2. Handling Missing Values\n",
    "# Missing values are common in datasets. We can handle them by either filling them with a value or dropping the rows/columns containing them.\n",
    "\n",
    "# Filling missing values\n",
    "df_filled = df.fillna({\n",
    "    'Name': 'Unknown',\n",
    "    'Age': df['Age'].mean(),  # Filling with mean age\n",
    "    'Gender': 'Unknown',\n",
    "    'Salary': df['Salary'].median()  # Filling with median salary\n",
    "})\n",
    "print(\"\\nData with Filled Missing Values:\")\n",
    "print(df_filled)\n",
    "\n",
    "# Dropping rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "print(\"\\nData with Dropped Missing Values:\")\n",
    "print(df_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba4d5d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data with a Duplicate Row:\n",
      "       Name   Age Gender   Salary  Start Date\n",
      "0     Alice  24.0      F  50000.0  2020-01-15\n",
      "1       Bob  27.0      M  54000.0  2019-03-22\n",
      "2   Charlie  22.0      M  50000.0  2018-06-30\n",
      "3     David  32.0      M  52000.0  2015-09-01\n",
      "4    Edward  29.0   None  58000.0  2016-10-12\n",
      "5      None  23.0      M  50000.0  2020-11-20\n",
      "6     Frank   NaN      M  59000.0  2017-02-10\n",
      "7     Grace  21.0      F      NaN  2018-07-19\n",
      "8    Hannah  25.0      F  60000.0  2019-08-25\n",
      "9       Ian  28.0      M  58000.0  2018-12-11\n",
      "10    David  32.0      M  52000.0  2015-09-01\n",
      "11    David  32.0      M  52000.0  2015-09-01\n",
      "12   Edward  29.0   None  58000.0  2016-10-12\n",
      "13     None  23.0      M  50000.0  2020-11-20\n",
      "14    Frank   NaN      M  59000.0  2017-02-10\n",
      "15    Grace  21.0      F      NaN  2018-07-19\n",
      "16   Hannah  25.0      F  60000.0  2019-08-25\n",
      "17      Ian  28.0      M  58000.0  2018-12-11\n",
      "18    David  32.0      M  52000.0  2015-09-01\n",
      "19    David  32.0      M  52000.0  2015-09-01\n",
      "\n",
      "Data with Duplicates Removed:\n",
      "      Name   Age Gender   Salary  Start Date\n",
      "0    Alice  24.0      F  50000.0  2020-01-15\n",
      "1      Bob  27.0      M  54000.0  2019-03-22\n",
      "2  Charlie  22.0      M  50000.0  2018-06-30\n",
      "3    David  32.0      M  52000.0  2015-09-01\n",
      "8   Hannah  25.0      F  60000.0  2019-08-25\n",
      "9      Ian  28.0      M  58000.0  2018-12-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idsc\\AppData\\Local\\Temp\\ipykernel_20040\\3297507591.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df.iloc[3], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ## 3. Removing Duplicates\n",
    "# Duplicates can skew our analysis, so we need to remove them.\n",
    "\n",
    "# Adding a duplicate row for demonstration\n",
    "df = df.append(df.iloc[3], ignore_index=True)\n",
    "print(\"\\nData with a Duplicate Row:\")\n",
    "print(df)\n",
    "\n",
    "# Removing duplicate rows\n",
    "df_no_duplicates = df_dropped.drop_duplicates()\n",
    "print(\"\\nData with Duplicates Removed:\")\n",
    "print(df_no_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1847b8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data with Converted Data Types:\n",
      "Name                  object\n",
      "Age                  float64\n",
      "Gender                object\n",
      "Salary                 int32\n",
      "Start Date    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ## 4. Data Type Conversions\n",
    "# Ensuring that each column has the correct data type is important for analysis.\n",
    "\n",
    "# Converting data types\n",
    "df_no_duplicates['Age'] = df_no_duplicates['Age'].astype(float)\n",
    "df_no_duplicates['Salary'] = df_no_duplicates['Salary'].astype(int)\n",
    "df_no_duplicates['Start Date'] = pd.to_datetime(df_no_duplicates['Start Date'])\n",
    "print(\"\\nData with Converted Data Types:\")\n",
    "print(df_no_duplicates.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab38c564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data with New 'Age Group' Column:\n",
      "      Name   Age Gender  Salary Start Date    Age Group\n",
      "0    Alice  24.0      F   50000 2020-01-15        Youth\n",
      "1      Bob  27.0      M   54000 2019-03-22  Young Adult\n",
      "2  Charlie  22.0      M   50000 2018-06-30        Youth\n",
      "3    David  32.0      M   52000 2015-09-01        Adult\n",
      "8   Hannah  25.0      F   60000 2019-08-25        Youth\n",
      "9      Ian  28.0      M   58000 2018-12-11  Young Adult\n"
     ]
    }
   ],
   "source": [
    "# ## 5. Basic Data Transformations\n",
    "# Sometimes we need to create new columns or modify existing ones.\n",
    "\n",
    "# Creating a new column 'Age Group'\n",
    "df_no_duplicates['Age Group'] = pd.cut(df_no_duplicates['Age'], bins=[0, 25, 30, 100], labels=['Youth', 'Young Adult', 'Adult'])\n",
    "print(\"\\nData with New 'Age Group' Column:\")\n",
    "print(df_no_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "160f8e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outliers in Salary:\n",
      "Empty DataFrame\n",
      "Columns: [Name, Age, Gender, Salary, Start Date, Age Group]\n",
      "Index: []\n",
      "\n",
      "Data with Outliers Removed:\n",
      "      Name   Age Gender  Salary Start Date    Age Group\n",
      "0    Alice  24.0      F   50000 2020-01-15        Youth\n",
      "1      Bob  27.0      M   54000 2019-03-22  Young Adult\n",
      "2  Charlie  22.0      M   50000 2018-06-30        Youth\n",
      "3    David  32.0      M   52000 2015-09-01        Adult\n",
      "8   Hannah  25.0      F   60000 2019-08-25        Youth\n",
      "9      Ian  28.0      M   58000 2018-12-11  Young Adult\n"
     ]
    }
   ],
   "source": [
    "# ## 6. Handling Outliers\n",
    "# Outliers can affect the analysis and models. Let's identify and handle them.\n",
    "\n",
    "# For simplicity, let's define outliers in the 'Salary' column as values beyond 1.5 * IQR (Interquartile Range)\n",
    "Q1 = df_no_duplicates['Salary'].quantile(0.25)\n",
    "Q3 = df_no_duplicates['Salary'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = df_no_duplicates[(df_no_duplicates['Salary'] < (Q1 - 1.5 * IQR)) | (df_no_duplicates['Salary'] > (Q3 + 1.5 * IQR))]\n",
    "print(\"\\nOutliers in Salary:\")\n",
    "print(outliers)\n",
    "\n",
    "# Removing outliers\n",
    "df_no_outliers = df_no_duplicates[~df_no_duplicates.isin(outliers)].dropna()\n",
    "print(\"\\nData with Outliers Removed:\")\n",
    "print(df_no_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a525f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data with Categorical Variables Encoded:\n",
      "      Name   Age  Salary Start Date  Gender_F  Gender_M  Age Group_Youth  \\\n",
      "0    Alice  24.0   50000 2020-01-15         1         0                1   \n",
      "1      Bob  27.0   54000 2019-03-22         0         1                0   \n",
      "2  Charlie  22.0   50000 2018-06-30         0         1                1   \n",
      "3    David  32.0   52000 2015-09-01         0         1                0   \n",
      "8   Hannah  25.0   60000 2019-08-25         1         0                1   \n",
      "9      Ian  28.0   58000 2018-12-11         0         1                0   \n",
      "\n",
      "   Age Group_Young Adult  Age Group_Adult  \n",
      "0                      0                0  \n",
      "1                      1                0  \n",
      "2                      0                0  \n",
      "3                      0                1  \n",
      "8                      0                0  \n",
      "9                      1                0  \n"
     ]
    }
   ],
   "source": [
    "# ## 7. Encoding Categorical Variables\n",
    "# Machine learning models require numerical inputs, so we need to encode categorical variables.\n",
    "\n",
    "# One-Hot Encoding for 'Gender' and 'Age Group'\n",
    "df_encoded = pd.get_dummies(df_no_outliers, columns=['Gender', 'Age Group'])\n",
    "print(\"\\nData with Categorical Variables Encoded:\")\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "669f78b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data with Scaled Features:\n",
      "      Name  Age  Salary Start Date  Gender_F  Gender_M  Age Group_Youth  \\\n",
      "0    Alice  0.2     0.0 2020-01-15         1         0                1   \n",
      "1      Bob  0.5     0.4 2019-03-22         0         1                0   \n",
      "2  Charlie  0.0     0.0 2018-06-30         0         1                1   \n",
      "3    David  1.0     0.2 2015-09-01         0         1                0   \n",
      "8   Hannah  0.3     1.0 2019-08-25         1         0                1   \n",
      "9      Ian  0.6     0.8 2018-12-11         0         1                0   \n",
      "\n",
      "   Age Group_Young Adult  Age Group_Adult  \n",
      "0                      0                0  \n",
      "1                      1                0  \n",
      "2                      0                0  \n",
      "3                      0                1  \n",
      "8                      0                0  \n",
      "9                      1                0  \n"
     ]
    }
   ],
   "source": [
    "# ## 8. Scaling/Normalizing Data\n",
    "# Features should be on a similar scale for better performance of machine learning models.\n",
    "\n",
    "# Normalizing 'Age' and 'Salary' using Min-Max Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_encoded[['Age', 'Salary']] = scaler.fit_transform(df_encoded[['Age', 'Salary']])\n",
    "print(\"\\nData with Scaled Features:\")\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e69acc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data with Renamed Columns:\n",
      "      Name  Age  Salary Start_Date  Gender_F  Gender_M  Age_Group_Youth  \\\n",
      "0    Alice  0.2     0.0 2020-01-15         1         0                1   \n",
      "1      Bob  0.5     0.4 2019-03-22         0         1                0   \n",
      "2  Charlie  0.0     0.0 2018-06-30         0         1                1   \n",
      "3    David  1.0     0.2 2015-09-01         0         1                0   \n",
      "8   Hannah  0.3     1.0 2019-08-25         1         0                1   \n",
      "9      Ian  0.6     0.8 2018-12-11         0         1                0   \n",
      "\n",
      "   Age_Group_Young_Adult  Age_Group_Adult  \n",
      "0                      0                0  \n",
      "1                      1                0  \n",
      "2                      0                0  \n",
      "3                      0                1  \n",
      "8                      0                0  \n",
      "9                      1                0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ## 9. Renaming Columns\n",
    "# For consistency and better understanding, let's rename some columns.\n",
    "\n",
    "df_renamed = df_encoded.rename(columns={'Start Date': 'Start_Date', 'Age Group_Youth': 'Age_Group_Youth', 'Age Group_Young Adult': 'Age_Group_Young_Adult', 'Age Group_Adult': 'Age_Group_Adult'})\n",
    "print(\"\\nData with Renamed Columns:\")\n",
    "print(df_renamed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bcaa246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data with Consistent Case in 'Name':\n",
      "      Name  Age  Salary Start_Date  Gender_F  Gender_M  Age_Group_Youth  \\\n",
      "0    Alice  0.2     0.0 2020-01-15         1         0                1   \n",
      "1      Bob  0.5     0.4 2019-03-22         0         1                0   \n",
      "2  Charlie  0.0     0.0 2018-06-30         0         1                1   \n",
      "3    David  1.0     0.2 2015-09-01         0         1                0   \n",
      "8   Hannah  0.3     1.0 2019-08-25         1         0                1   \n",
      "9      Ian  0.6     0.8 2018-12-11         0         1                0   \n",
      "\n",
      "   Age_Group_Young_Adult  Age_Group_Adult  \n",
      "0                      0                0  \n",
      "1                      1                0  \n",
      "2                      0                0  \n",
      "3                      0                1  \n",
      "8                      0                0  \n",
      "9                      1                0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## 10. Handling Inconsistent Data\n",
    "# Ensuring consistency in data, such as case consistency in categorical variables.\n",
    "\n",
    "# Converting 'Name' to title case\n",
    "df_renamed['Name'] = df_renamed['Name'].str.title()\n",
    "print(\"\\nData with Consistent Case in 'Name':\")\n",
    "print(df_renamed)\n",
    "\n",
    "# ## Conclusion\n",
    "# In this notebook, we covered the basics of data cleaning and some advanced techniques including handling missing values, removing duplicates, converting data types, handling outliers, encoding categorical variables, scaling data, renaming columns, and ensuring data consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84532424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
